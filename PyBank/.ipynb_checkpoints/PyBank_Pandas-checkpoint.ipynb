{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        ############################################NOTE: 03/12/2018#################################################\n",
    "    #I failed to properly edit the 'Date' attribute between the two csv documents in order to have a single index\n",
    "    #which I would have used to join the two files. Concatenating would have not been permissible given that we've\n",
    "    #duplicate Date values, which would have created redundancy. I wanted to merge (i.e. sum) the matching values by Date.\n",
    "    \n",
    "    #Subsequently I did not join my CSVs, which would have then worked fine to output my final summary (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "csv1 = os.path.join('Resource', 'budget_data_1.csv')\n",
    "csv2 = os.path.join('Resource', 'budget_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv using Pandas and print out the DataFrame that is returned\n",
    "csv1_df = pd.read_csv(csv1)\n",
    "csv2_df = pd.read_csv(csv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Date  Revenue\n",
       "0   Oct-12  1154293\n",
       "1   Nov-12   885773\n",
       "2   Dec-12  -448704\n",
       "3   Jan-13   563679\n",
       "4   Feb-13   555394\n",
       "5   Mar-13   631974\n",
       "6   Apr-13   957395\n",
       "7   May-13  1104047\n",
       "8   Jun-13   693464\n",
       "9   Jul-13   454932\n",
       "10  Aug-13   727272\n",
       "11  Sep-13   125016\n",
       "12  Oct-13   339251\n",
       "13  Nov-13    78523\n",
       "14  Dec-13   977084\n",
       "15  Jan-14  1158718\n",
       "16  Feb-14   332681\n",
       "17  Mar-14  -341227\n",
       "18  Apr-14   173826\n",
       "19  May-14   742611\n",
       "20  Jun-14  1189806\n",
       "21  Jul-14   607363\n",
       "22  Aug-14 -1172384\n",
       "23  Sep-14   587993\n",
       "24  Oct-14   295198\n",
       "25  Nov-14  -300390\n",
       "26  Dec-14   468995\n",
       "27  Jan-15   698452\n",
       "28  Feb-15   967828\n",
       "29  Mar-15  -454873\n",
       "30  Apr-15   375723\n",
       "31  May-15  1140526\n",
       "32  Jun-15    83836\n",
       "33  Jul-15   413189\n",
       "34  Aug-15   551363\n",
       "35  Sep-15  1195111\n",
       "36  Oct-15   657081\n",
       "37  Nov-15    66659\n",
       "38  Dec-15   803301\n",
       "39  Jan-16  -953301\n",
       "40  Feb-16   883934>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv1_df.head #has 41 rows; i.e. 41 months worth of data between Oct. 12 - Feb. 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Date  Revenue\n",
       "0   Jan-2009   943690\n",
       "1   Feb-2009  1062565\n",
       "2   Mar-2009   210079\n",
       "3   Apr-2009  -735286\n",
       "4   May-2009   842933\n",
       "5   Jun-2009   358691\n",
       "6   Jul-2009   914953\n",
       "7   Aug-2009   723427\n",
       "8   Sep-2009  -837468\n",
       "9   Oct-2009  -146929\n",
       "10  Nov-2009   831730\n",
       "11  Dec-2009   917752\n",
       "12  Jan-2010   800038\n",
       "13  Feb-2010  1117103\n",
       "14  Mar-2010   181220\n",
       "15  Apr-2010   120968\n",
       "16  May-2010   844012\n",
       "17  Jun-2010   307468\n",
       "18  Jul-2010   502341\n",
       "19  Aug-2010  -748679\n",
       "20  Sep-2010 -1063151\n",
       "21  Oct-2010   111367\n",
       "22  Nov-2010   889322\n",
       "23  Dec-2010  1028794\n",
       "24  Jan-2011  -705201\n",
       "25  Feb-2011   457393\n",
       "26  Mar-2011   358440\n",
       "27  Apr-2011   110092\n",
       "28  May-2011  1111337\n",
       "29  Jun-2011   691712\n",
       "..       ...      ...\n",
       "56  Sep-2013   339680\n",
       "57  Oct-2013   809253\n",
       "58  Nov-2013   924494\n",
       "59  Dec-2013   998347\n",
       "60  Jan-2014  -524902\n",
       "61  Feb-2014   747765\n",
       "62  Mar-2014   197783\n",
       "63  Apr-2014   131625\n",
       "64  May-2014  1016992\n",
       "65  Jun-2014  -930753\n",
       "66  Jul-2014   714387\n",
       "67  Aug-2014   201005\n",
       "68  Sep-2014   655535\n",
       "69  Oct-2014   845108\n",
       "70  Nov-2014   101736\n",
       "71  Dec-2014   -93063\n",
       "72  Jan-2015   984921\n",
       "73  Feb-2015  -362343\n",
       "74  Mar-2015   940457\n",
       "75  Apr-2015   216399\n",
       "76  May-2015   363036\n",
       "77  Jun-2015   672160\n",
       "78  Jul-2015   783533\n",
       "79  Aug-2015  1079882\n",
       "80  Sep-2015   288933\n",
       "81  Oct-2015   894500\n",
       "82  Nov-2015   411593\n",
       "83  Dec-2015   789575\n",
       "84  Jan-2016   355838\n",
       "85  Feb-2016   437489\n",
       "\n",
       "[86 rows x 2 columns]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv2_df.head #has 86 rows; i.e. 41 months worth of data between Jan. 2009 - Feb. 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-194-268b01626207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplacement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfindlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplacelist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#csv1_dfc.write(s)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "#I first need to combine the two tables by a common attribute, i.e. Date, and combine the Revenue for matching Dates.\n",
    "    #Need to edit the Date formatting to match between the two CSV docs.\n",
    "    #The \"find and replace\" strategy is due to my inability to figure out a way to universally convert the dates to a \n",
    "    #single standard, which is the desired function if this script is to work for batch processes.\n",
    "\n",
    "    ###########################################Code did not work#####################################################\n",
    "    \n",
    "##Method 1, replace the 'year' value to create a common index to join/merge between csv 1 and 2:\n",
    "findlist = ['12','13','14','15','16']\n",
    "replacelist = ['2012','2013','2014','2015','2016']\n",
    "\n",
    "def findReplace(find, replace):\n",
    "    s = csv1_df.read()\n",
    "    s = s.replace(Date, replacement)\n",
    "    csv1_dfc.write(s)\n",
    "\n",
    "for item, replacement in zip(findlist, replacelist):\n",
    "    s = s.replace(Date, replacement)\n",
    "    csv1_dfc.write(s)\n",
    "\n",
    "##Method 2 to find and replace:\n",
    "csv1_dfc = csv1_df\n",
    "csv1_dfc['Date'] = csv1_dfc['Date'].replace({'12':'2012', '13': '2013'})\n",
    "\n",
    "##To merge\n",
    "    #merge_csv = csv2_df.merge(csv1_df, on='Date')\n",
    "    #merge_csv.to_csv(\"output.csv\", index=False)\n",
    "    #print(merge_csv)\n",
    "    #merged_left = pd.merge(left=csv2_df,right=csv1_df, how='left', left_on='Date', right_on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########Below is what I would have ran for the combine csv; tried with just one to confirm whether the code worked############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * The total number of months included in the dataset\n",
    "count_month = csv1_df['Date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * The total amount of revenue gained over the entire period\n",
    "total_revenue = csv1_df['Revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * The average change in revenue between months over the entire period\n",
    "avg_revenue = csv1_df['Revenue'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * The greatest increase in revenue (date and amount) over the entire period\n",
    "max_revenue = csv1_df['Revenue'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * The greatest decrease in revenue (date and amount) over the entire period\n",
    "min_revenue = csv1_df['Revenue'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Analysis\n",
      "-------------------------\n",
      "Total Months: 41\n",
      "Total Revenue: $18971412\n",
      "Average Revenue Change: $462717.3658536585\n",
      "Greatest Increase in Revenue: $1195111\n",
      "Greatest Decrease in Revenue: $-1172384\n"
     ]
    }
   ],
   "source": [
    "print(\"Financial Analysis\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Total Months: \" + str(count_month))\n",
    "print(\"Total Revenue: $\" + str(total_revenue))\n",
    "print(\"Average Revenue Change: $\" + str(avg_revenue))\n",
    "print(\"Greatest Increase in Revenue: $\" + str(max_revenue))\n",
    "print(\"Greatest Decrease in Revenue: $\" + str(min_revenue))\n",
    "\n",
    "# Financial Analysis\n",
    "    # ----------------------------\n",
    "    # Total Months: 25\n",
    "    # Total Revenue: $1241412\n",
    "    # Average Revenue Change: $216825\n",
    "    # Greatest Increase in Revenue: Sep-16 ($815531)\n",
    "    # Greatest Decrease in Revenue: Aug-12 ($-652794)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
